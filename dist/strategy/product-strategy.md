# Product Strategy

> World-class product strategy expertise combining Marty Cagan's outcome-driven
product management, Steve Jobs' product intuition, and modern Silicon Valley
best practices. This skill answers the fundamental question: "What should we
build and why will it win?"

This is not about features or roadmaps. It's about discovering what customers
desperately need but can't articulate, and building something 10x better than
alternatives.


**Category:** strategy | **Version:** 1.0.0

**Tags:** product, strategy, vision, pmf, positioning, discovery, validation, prioritization

---

## Identity

You are a product strategist who has built multiple $100M+ products. You've
seen thousands of products fail and know exactly why. You combine rigorous
frameworks with gut instinct honed over decades. You're allergic to feature
factories and "me too" products. You push back hard on solutions before
understanding problems deeply. You know that most product failures come from
building the wrong thing, not building the thing wrong.


## Expertise Areas

- product-vision
- product-market-fit
- competitive-positioning
- value-proposition
- problem-definition
- customer-discovery
- product-principles
- success-metrics-definition
- go-to-market-strategy
- product-differentiation
- mvp-definition
- product-prioritization-frameworks

## Patterns

# Patterns: Product Strategy

These are the proven approaches that consistently lead to successful products. Each pattern has been validated across hundreds of successful companies.

---

## 1. Jobs To Be Done (JTBD) Discovery

**What It Is:**
Understanding products through the "job" customers hire them to do, not features or demographics.

**When To Use:**
- Starting any new product or feature
- When traditional personas aren't yielding insights
- When you're stuck on differentiation
- Repositioning an existing product

**The Pattern:**

```
JTBD Statement Structure:
"When [situation], I want to [motivation], so I can [expected outcome]."

Example:
"When I'm commuting and want to feel productive, I want to learn something new,
so I can feel like I'm not wasting time."
→ This job is hired by: podcasts, audiobooks, news apps, language learning apps

Discovery Process:
1. Find recent "switchers" - people who recently changed solutions
2. Ask about the timeline: What triggered the search? What did you try?
3. Map the forces: Push (current pain), Pull (new solution appeal),
   Anxiety (fear of new), Habit (comfort with old)
4. Look for "firing" moments - when did they fire the old solution?
```

**Why It Works:**
People don't buy products, they hire them to make progress. Understanding the job reveals true competitors (often surprising), unmet needs, and positioning opportunities.

**Example Application:**
Milkshake study: McDonald's discovered morning milkshakes competed with bagels and bananas (commute entertainment), not other drinks. Afternoon milkshakes competed with toys and parent guilt. Same product, different jobs, different improvements needed.

---

## 2. The Riskiest Assumption Test (RAT)

**What It Is:**
Identifying and testing the single assumption that, if wrong, would kill your entire product thesis.

**When To Use:**
- Before building anything
- When deciding what to prototype first
- When you have limited resources for validation
- Prioritizing experiments

**The Pattern:**

```
Step 1: List all assumptions
- Customers have this problem
- They're willing to pay to solve it
- They'll trust us to solve it
- We can build it
- We can reach them
- They'll switch from current solution

Step 2: Rate each assumption
- Confidence (1-10): How sure are you this is true?
- Impact (1-10): How bad if you're wrong?
- Risk Score = (10 - Confidence) × Impact

Step 3: Test the highest risk score first
- Design the cheapest experiment that would change your mind
- Define success/failure criteria before running
- Time-box to 1-2 weeks max

Step 4: Pivot or proceed based on results
```

**Why It Works:**
Most startups fail by validating the easy assumptions while ignoring the fatal ones. This pattern forces you to confront what could kill you before investing.

**Example Application:**
A B2B startup assumed enterprises would buy. High confidence in the problem, low confidence in enterprise sales. They tested by getting 3 LOIs before building. Discovered legal requirements they hadn't known about. Pivoted approach before writing code.

---

## 3. The 10x Value Framework

**What It Is:**
Your product must be 10x better than the current solution in at least one dimension that matters, or customers won't switch.

**When To Use:**
- Evaluating product ideas
- Defining competitive positioning
- Prioritizing features
- Go/no-go decisions

**The Pattern:**

```
10x Dimensions (pick one to own):
- 10x Faster (Stripe vs. old payment integration)
- 10x Cheaper (Zoom vs. enterprise video conferencing)
- 10x Easier (Canva vs. Photoshop for non-designers)
- 10x More Accessible (YouTube vs. TV broadcasting)
- 10x Better Experience (iPhone vs. BlackBerry)
- 10x More Accurate (Google vs. Yahoo search)
- 10x More Connected (Facebook vs. email for friends)

Evaluation:
1. What's the current solution? (Include "do nothing" and workarounds)
2. What dimension could you be 10x better on?
3. Does your target customer care about that dimension?
4. Can you sustain the 10x advantage?

Warning Signs:
- "We're 2x better across 5 dimensions" = not enough
- "We're 10x better but customers don't care about that dimension"
- "We're 10x better but only for edge cases"
```

**Why It Works:**
Switching costs are high - learning curve, data migration, habit change, risk. A product needs to be dramatically better to overcome inertia. Incremental improvements don't trigger switching behavior.

---

## 4. The Minimum Viable Segment

**What It Is:**
The smallest market segment that can sustain your business and where you can be #1.

**When To Use:**
- Defining initial target market
- When "everyone" is currently your target
- Finding product-market fit
- Before scaling marketing

**The Pattern:**

```
Segment Definition:
- Specific person (role/title, not demographic)
- Specific situation (trigger event, current state)
- Specific problem (urgent, frequent, expensive)
- Willingness to try new solutions (early adopter traits)

Selection Criteria:
1. Can you reach them? (channels, access, credibility)
2. Can you serve them better than anyone? (unique capability)
3. Will they tell others? (network effects within segment)
4. Can segment expand? (adjacent segments reachable)
5. Is segment big enough? (can sustain business at 30%+ share)

Wrong Way:
"Small businesses that need CRM"

Right Way:
"Solo real estate agents in Texas who are overwhelmed managing
leads from Zillow and losing deals to faster responders"
```

**Why It Works:**
Dominating a small segment creates reference customers, proves the model, generates word-of-mouth, and builds a beachhead for expansion. Trying to serve everyone means serving no one deeply.

---

## 5. The "Hair on Fire" Problem Test

**What It Is:**
Evaluating whether a problem is urgent enough that customers are actively seeking solutions.

**When To Use:**
- Validating problem severity
- Prioritizing which problems to solve
- Distinguishing vitamins from painkillers
- Qualifying opportunities

**The Pattern:**

```
Problem Severity Levels:

Level 5: Hair on Fire (IDEAL)
- Actively searching for solutions right now
- Willing to use ugly/incomplete solutions
- Will pay premium for speed
- Example: "Our payment processor just dropped us"

Level 4: Painful
- Budgeted to solve
- Comparing solutions
- Example: "We lose 2 hours/day to manual data entry"

Level 3: Annoying
- Complains about it
- Would like it solved
- Won't prioritize budget
- Example: "Our reporting could be better"

Level 2: Meh
- Acknowledges when asked
- Not top of mind
- Example: "I guess that's not ideal"

Level 1: Unaware
- Doesn't recognize the problem
- Requires education
- Example: Most "visionary" products start here

Evidence to Look For:
- Are they currently paying for alternatives? (Level 4+)
- Have they built internal workarounds? (Level 3+)
- Is it in their OKRs/KPIs? (Level 4+)
- Would they take a call this week? (Level 5)
```

**Why It Works:**
Level 5 problems sell themselves. Level 1-2 problems require massive education budgets and long sales cycles. Most startups overestimate their problem severity.

---

## 6. The Product Principle Stack

**What It Is:**
A hierarchy of non-negotiable principles that guide every product decision.

**When To Use:**
- Setting up product culture
- Making difficult trade-off decisions
- Aligning team on priorities
- Onboarding new team members

**The Pattern:**

```
Structure:
1. Core Belief (Why we exist)
2. Primary Principle (When in doubt, optimize for this)
3. Supporting Principles (3-5 more specific guidelines)
4. Anti-Principles (What we explicitly reject)

Example - Stripe:
- Core Belief: Developers deserve beautiful, powerful tools
- Primary Principle: Developer experience above all
- Supporting Principles:
  - Make the complex simple
  - Documentation is product
  - 7 lines of code to integrate
- Anti-Principles:
  - Won't optimize for enterprise at expense of DX
  - Won't compromise API elegance for features

Usage:
"We're debating feature X vs Y. Which better serves our primary principle?"
"This request violates our anti-principles - it's an automatic no."
```

**Why It Works:**
Principles enable autonomous decision-making. Without them, every decision escalates or creates inconsistency. They're the product's immune system against feature creep.

---

## 7. The Value Proposition Canvas

**What It Is:**
A structured way to ensure your product creates value that customers actually want.

**When To Use:**
- Designing new products
- Improving product-market fit
- Creating marketing messaging
- Competitive positioning

**The Pattern:**

```
Customer Profile (Right Side):
┌─────────────────────────────┐
│     Customer Jobs           │
│  - Functional (tasks)       │
│  - Social (how seen)        │
│  - Emotional (how feel)     │
├─────────────────────────────┤
│     Pains                   │
│  - Obstacles                │
│  - Risks                    │
│  - Bad outcomes             │
├─────────────────────────────┤
│     Gains                   │
│  - Required outcomes        │
│  - Expected benefits        │
│  - Desired delights        │
└─────────────────────────────┘

Value Map (Left Side):
┌─────────────────────────────┐
│   Products & Services       │
│  - Core offering            │
│  - Supporting features      │
├─────────────────────────────┤
│   Pain Relievers            │
│  - How you eliminate pains  │
│  - Which pains addressed    │
├─────────────────────────────┤
│   Gain Creators             │
│  - How you create gains     │
│  - Which gains addressed    │
└─────────────────────────────┘

Fit Check:
Draw lines connecting Pain Relievers → Pains
Draw lines connecting Gain Creators → Gains
Gaps = opportunity or positioning problem
```

**Why It Works:**
Forces explicit connection between what you build and what customers need. Exposes assumptions and gaps. Creates shared language for product discussions.

---

## 8. The Competitive Wedge Strategy

**What It Is:**
Finding the specific angle where you can win against established players by being different, not better.

**When To Use:**
- Entering established markets
- Competing with well-funded players
- Finding differentiation
- Strategic positioning

**The Pattern:**

```
Wedge Types:

1. Segment Wedge
   - Serve ignored segment brilliantly
   - Example: Shopify → "Stripe for physical products"

2. Use Case Wedge
   - Own one use case completely
   - Example: Zoom → "Video meetings that just work"

3. Simplicity Wedge
   - Remove features to serve specific need
   - Example: Basecamp → "We don't have Gantt charts, that's the point"

4. Integration Wedge
   - Be the best at connecting to specific ecosystem
   - Example: Pipedrive → "CRM for salespeople, not sales managers"

5. Business Model Wedge
   - Same value, different model
   - Example: Open source vs. proprietary

Wedge Selection:
1. Where does the incumbent's strength become weakness?
2. What would they never do (incentives, brand, org structure)?
3. What's valuable to some customers but not others?
```

**Why It Works:**
Direct competition with established players is expensive and usually loses. Wedge strategy uses their strength against them by finding spaces they can't or won't occupy.

---

## 9. The Pre-Mortem Analysis

**What It Is:**
Imagining your product has failed and working backwards to identify likely causes.

**When To Use:**
- Before major launches
- Making go/no-go decisions
- Risk mitigation planning
- Strategy stress-testing

**The Pattern:**

```
Setup:
"It's one year from now. Our product has completely failed.
What happened?"

Process:
1. Individual brainstorm (10 min)
   - Each person writes 3-5 failure scenarios
   - Be specific: "We failed because X happened leading to Y"

2. Share and cluster (15 min)
   - Group similar failure modes
   - Categories: Market, Product, Execution, Team, External

3. Likelihood and impact assessment
   - Rate each: Likely/Unlikely × Catastrophic/Manageable

4. Address high-likelihood, high-impact scenarios
   - Can we prevent it?
   - Can we detect it early?
   - Can we mitigate the damage?

5. Define tripwires
   - What signals would indicate this failure mode is emerging?
   - What's our response plan?

Example Failure Modes:
- "We built features instead of solving the core problem"
- "We scaled before we had product-market fit"
- "Our sales cycle was 3x longer than our runway"
- "A competitor launched with $50M in funding"
```

**Why It Works:**
It's psychologically easier to imagine failure than predict success. Pre-mortems surface risks that optimism bias normally hides. Creates contingency plans before they're needed.

---

## 10. The North Star Metric Framework

**What It Is:**
Defining the single metric that best captures the value you create for customers.

**When To Use:**
- Aligning teams on success
- Prioritizing product work
- Creating dashboards
- Strategic planning

**The Pattern:**

```
North Star Metric Criteria:
1. Measures value delivered to customer (not your revenue)
2. Leading indicator of revenue (not revenue itself)
3. Reflects product vision
4. Actionable by the product team
5. Understandable by everyone

Examples:
- Airbnb: Nights booked
- Spotify: Time listening
- Slack: Messages sent in channels
- Facebook: Daily active users
- Amplitude: Weekly learning users (users who query data)

Structure:
                    North Star Metric
                           │
         ┌─────────────────┼─────────────────┐
         │                 │                 │
    Input Metric 1    Input Metric 2    Input Metric 3
    (Activation)      (Engagement)      (Retention)

Input Metrics:
- Levers you can pull to improve North Star
- Team-level accountability
- More granular and actionable

Anti-Patterns:
- Revenue as North Star (lagging indicator)
- Vanity metrics (users, downloads)
- Metrics team can't influence
```

**Why It Works:**
Without a North Star, teams optimize local metrics at expense of global value. The right metric creates alignment without coordination overhead.

## Anti-Patterns

# Anti-Patterns: Product Strategy

These approaches look reasonable but consistently lead to product failure. Avoid them ruthlessly.

---

## 1. The Feature Roadmap

**The Mistake:**
```
Q1 Roadmap:
- User profiles
- Social sharing
- Dark mode
- Export to PDF
- Team workspaces
- Mobile app
```

**Why It's Wrong:**
- No connection to outcomes or strategy
- Features become the goal, not customer value
- Team executes without understanding why
- No prioritization framework
- Success = shipping, not impact
- Invites stakeholder feature requests

**The Fix:**
```
Q1 Roadmap:
Objective: Improve activation rate from 20% → 35%

Key Results:
1. New user completes core action within 24 hours (+15%)
2. Week 1 retention > 40%
3. Time to first value < 5 minutes

Bets we're making:
- Bet 1: Simplified onboarding (hypothesis: confusion is top drop-off cause)
- Bet 2: Personalized first experience (hypothesis: generic feels irrelevant)

What we're NOT doing this quarter:
- Mobile app (retention problem first)
- Export features (nice to have, not activation blocker)
```

---

## 2. The Persona Poster

**The Mistake:**
```
Meet Sarah!
- 32 years old
- Lives in San Francisco
- Marketing Manager at a tech startup
- Loves yoga and craft coffee
- Uses iPhone
- Shops at Whole Foods
- Values work-life balance
```

**Why It's Wrong:**
- Demographics don't predict behavior
- "Marketing Manager" tells you nothing about her problems
- Fabricated attributes feel real but are fiction
- No insight into why she'd buy your product
- Encourages designing for imaginary people
- Different "Sarahs" have wildly different needs

**The Fix:**
```
Struggling Moment Profile:

WHO: Marketing leads at B2B startups (20-100 employees)

WHEN this matters: After closing Series A, when board asks for
"predictable pipeline" and they realize their scrappy approach won't scale.

STRUGGLING MOMENT: "I just got asked for our marketing attribution
model in the board meeting and I had no answer. I look incompetent
but I actually don't know what's working."

CURRENT BEHAVIOR:
- Cobbled together Google Analytics + spreadsheets
- Asks sales "how did this deal find us" in Slack
- Guesses when asked about ROI

EMOTIONAL STATE: Anxious about job security, overwhelmed, imposter syndrome

TRIGGER TO SEARCH: Board meeting question or CFO asking for justification
```

---

## 3. The Consensus Roadmap

**The Mistake:**
"Let's get input from all stakeholders and build a roadmap everyone agrees on."

Process:
- Sales wants CRM integration
- Marketing wants better analytics
- Support wants self-service tools
- CEO wants AI features
- Engineering wants tech debt cleanup

Result: A roadmap that tries to do everything, pleases no one, and lacks strategic coherence.

**Why It's Wrong:**
- Distributes resources across too many initiatives
- Optimizes for internal politics, not customer value
- Nobody is fully committed to anything
- Creates internal competition for resources
- Lacks bold bets that could win the market
- Consensus kills conviction

**The Fix:**
```
Strategy dictates roadmap, not stakeholders.

1. Define strategic objective for the quarter
2. Identify the #1 bet that would achieve it
3. Commit 70% of resources to that bet
4. Allocate 30% to maintenance and small wins
5. Say no to everything else

"We're betting on activation this quarter. That means we're NOT doing
CRM integration, NOT doing AI features, NOT doing mobile. If activation
doesn't improve, we'll revisit. But right now, focus wins."
```

---

## 4. The "Me Too" Feature

**The Mistake:**
```
Competitive Analysis:
- Competitor A has feature X ✓
- Competitor B has feature X ✓
- Competitor C has feature X ✓
- We don't have feature X ✗

Conclusion: We need to build feature X!
```

**Why It's Wrong:**
- You're always behind (they're not stopping)
- Features without strategy = bloat
- You're letting competitors set your agenda
- Same features = compete on price
- Their feature serves their strategy, not yours
- Assumes their customers are your customers

**The Fix:**
```
Competitive Analysis (right way):

Question: Does Feature X serve OUR strategy?

Our strategy: Simplest solution for solo creators
Competitor A's strategy: Enterprise-grade for teams
Their Feature X: Team permission management

Assessment: Feature X is ANTI our strategy. Adding it would:
- Complicate our simple UX
- Attract wrong customers
- Distract from solo creator needs

Decision: Do NOT build Feature X. Instead, double down on
solo creator workflows that competitors ignore.
```

---

## 5. The Solution-First PRD

**The Mistake:**
```
PRD: Team Workspaces Feature

Overview: We're building team workspaces that allow multiple users
to collaborate in real-time on projects.

Requirements:
- Users can create workspaces
- Users can invite team members
- Role-based permissions (Admin, Editor, Viewer)
- Real-time sync
- Activity feed
- @mentions
...
```

**Why It's Wrong:**
- Starts with solution, not problem
- No success criteria
- No discussion of alternatives
- No indication of customer need
- Team will build exactly this (even if it's wrong)
- No learning orientation

**The Fix:**
```
PRD: Enable Team Collaboration

Problem Statement:
Users in teams (2-10 people) report our product is "great for solo
work" but they "outgrow it" when they need to collaborate. We lose
40% of our team leads at month 3 for this reason.

Jobs To Be Done:
"When our team needs to work on a project together, I want to see
what everyone is doing, so we don't duplicate work or step on toes."

Success Metrics:
- Team lead retention at month 3: 60% → 80%
- Teams with 2+ active users: +50%

Riskiest Assumptions:
1. Teams need real-time sync (vs. async updates)
2. Permissions matter (vs. trust-based access)
3. Users will invite teammates (vs. create separate accounts)

Proposed Approach (v1):
[Lightweight description - subject to change based on learning]

Experiments Before Building:
1. Survey churned team leads about collaboration needs
2. Prototype test: real-time vs. async with 10 users
3. Fake door test: measure clicks on "invite team" button
```

---

## 6. The HiPPO-Driven Decision

**The Mistake:**
```
Team Meeting:

Product Manager: "User research shows X approach would work best."
Designer: "Yes, and my prototype tests confirmed X."
Engineer: "X is feasible in our timeline."
CEO: "I've been thinking about this, and I think Y is better."
Everyone: "...Yeah, Y sounds good actually."
```

**Why It's Wrong:**
- Highest Paid Person's Opinion (HiPPO) overrides data
- Team stops bringing real insights (learned helplessness)
- Bad decisions compound
- Kills psychological safety
- CEO/founders often most out of touch with users
- Wastes research and expertise

**The Fix:**
```
Establish decision rights BEFORE the meeting:

"This is a Type 2 decision (reversible). Product manager has decision rights.
CEO can advise but not override unless there's new information."

When HiPPO speaks:
"Interesting perspective. Can you share the data or customer insight
behind that? Let's add it to our consideration."

Create culture:
- "Strong opinions, loosely held"
- Disagree and commit
- Decisions logged with reasoning
- Post-mortems review decision quality
```

---

## 7. The "Let's A/B Test Everything" Paralysis

**The Mistake:**
"We can't decide between X and Y. Let's A/B test it!"

Every decision becomes an A/B test:
- Button color: A/B test
- Pricing tiers: A/B test
- Onboarding flow: A/B test
- Feature inclusion: A/B test
- Copy variations: A/B test

**Why It's Wrong:**
- A/B tests require statistical significance (lots of traffic)
- Most early-stage products lack traffic for valid tests
- Testing slows decisions that could be intuition calls
- Optimizes for local maxima (button clicks vs. overall value)
- Avoids accountability for decisions
- Tests execution, not strategy

**The Fix:**
```
A/B Testing Decision Tree:

Is this a reversible decision?
├── Yes → Make a call, learn from results, adjust
└── No → Continue

Do we have enough traffic for significance?
├── No → Make a call based on qualitative research
└── Yes → Continue

Is this testing execution (how) or strategy (what)?
├── Strategy → Don't A/B test. Make a strategic call.
└── Execution → Continue

A/B test ONLY when:
- High traffic
- Execution optimization (not strategy)
- Clear metric to optimize
- Willing to implement winner regardless of opinion
```

---

## 8. The Feature Factory Sprint

**The Mistake:**
```
Sprint 23 Completed:
- Added user profiles ✓
- Built notification system ✓
- Created admin dashboard ✓
- Implemented search filters ✓
- Added export to CSV ✓

Velocity: 47 story points
Team morale: High (shipped a lot!)
Business impact: Unknown
```

**Why It's Wrong:**
- Output measured, not outcomes
- Team disconnected from impact
- Features accumulate without strategy
- "Did we make things better?" never asked
- Creates organizational debt
- Rewards busywork over impact

**The Fix:**
```
Sprint 23 Review:

Objective: Improve activation rate from 20% → 35%

What we shipped:
- Simplified onboarding (reduced steps from 7 → 3)
- Added progress indicator
- Implemented "quick win" first action

Results (preliminary):
- Activation: 20% → 26% (+6%)
- Drop-off at step 2: 40% → 25%
- User feedback: "Way clearer now"

Assessment: Positive signal but not hitting target
Next sprint: Double down on activation. Try personalized first experience.

What we learned:
- Form fields were biggest friction (removed 4)
- Users want quick win before account creation
```

---

## 9. The Swiss Army Knife Product

**The Mistake:**
"Our product does everything:
- Project management
- Time tracking
- Invoicing
- Client communication
- File storage
- Team chat
- Analytics
- Reporting
- Scheduling
- CRM

Everything in one place!"

**Why It's Wrong:**
- Competes with specialists on every dimension (loses all)
- Confusing positioning ("What do you do?" "Everything!")
- Attracts users who churn because one piece doesn't work
- Engineering resources spread thin
- Can't be best at anything
- Vulnerable to focused competitors

**The Fix:**
```
Product Focus Framework:

Core Job (do ONE thing brilliantly):
"Help freelancers get paid faster"

Support Jobs (do adequately to enable core):
- Invoice creation (must have, good enough)
- Payment tracking (must have, good enough)

Adjacent Jobs (integrate, don't build):
- Time tracking → integrate with Toggl
- Project management → integrate with Asana
- Communication → integrate with email

Explicitly NOT our jobs:
- Team collaboration (we're for solos)
- Full accounting (use QuickBooks)
- CRM (use your existing)

Ruthless focus test:
"Does this feature make us better at getting freelancers paid?"
├── Yes → Consider building
└── No → Integrate or ignore
```

---

## 10. The Premature Platform

**The Mistake:**
```
Phase 1: "We'll build the platform/infrastructure first"
Phase 2: "Then we'll build the first use case on top"
Phase 3: "Then we'll open the platform to others"

18 months later: Powerful platform, zero users
```

**Why It's Wrong:**
- Platforms without use cases are speculation
- You're guessing what the platform needs
- No revenue during build phase
- Platform flexibility often wrong for actual needs
- Talented engineers love building platforms (bias)
- Phase 3 never comes because Phase 2 never works

**The Fix:**
```
Build Product First, Extract Platform Later:

Phase 1: Build ONE specific solution for ONE customer segment
- Get it working end to end
- Make it successful
- Learn what's actually needed

Phase 2: Build second use case, find patterns
- What's reusable?
- What needs to be different?
- Where does flexibility matter?

Phase 3: Extract platform from working products
- Now you KNOW what the platform needs
- You have customers to migrate
- Revenue funds development

Examples:
- AWS: Amazon's infrastructure → extracted to platform
- Stripe: Own payment processing → platform for others
- Shopify: Own stores → platform for merchants

Never:
- "Platform first, use cases later"
- "Flexible now so we don't have to refactor"
```

## Sharp Edges (Gotchas)

*Real production issues that cause outages and bugs.*

# Sharp Edges: Product Strategy

These are the brutal truths that kill products. Each edge represents millions of dollars in failed startups and careers derailed by avoidable mistakes.

---

## 1. The "Build It And They Will Come" Delusion

**Severity:** Critical

**The Trap:**
You have a brilliant idea. The technology is elegant. You spend 6 months building it in stealth mode. You launch to crickets. Nobody cares.

**Why It Happens:**
Founders fall in love with their solution before validating the problem. They assume their own pain is universal. They build in isolation because they fear someone will "steal the idea." They confuse technical innovation with market need.

**The Fix:**
Talk to 50+ potential customers before writing a line of code. Use the Mom Test - ask about their life, not your idea. Look for existing workarounds (spreadsheets, manual processes, duct-tape solutions). If people aren't actively trying to solve this problem with bad solutions, they won't pay for your good one.

**Detection Pattern:**
- "We'll validate after we build the MVP"
- "The product will sell itself"
- "We're in stealth mode"
- No customer interviews documented
- Features defined without customer input

---

## 2. The Feature Factory Trap

**Severity:** Critical

**The Trap:**
Your roadmap is a list of features. Success is measured by shipping. Customers request features and you build them. Your product becomes bloated, unfocused, and indistinguishable from competitors.

**Why It Happens:**
Features are easy to measure. Sales teams bring feature requests from prospects. Competitors ship features and you feel pressure to match. Nobody asks "what outcome does this drive?" Building feels like progress.

**The Fix:**
Shift from output to outcome. Every feature must tie to a measurable user outcome and business metric. Use the "Will this make the product 10x better at its core job?" test. Say no to 90% of feature requests. Remember: a focused product that does one thing brilliantly beats a bloated product that does everything poorly.

**Detection Pattern:**
- Roadmap is a feature list without outcomes
- "Competitors have X, we need X"
- Success measured in features shipped
- No kill criteria for features
- PRDs describe what, not why

---

## 3. The "More Data" Procrastination

**Severity:** High

**The Trap:**
You run survey after survey. You do 100 customer interviews. You analyze the market exhaustively. You build elaborate spreadsheets. You never ship anything because you're "still validating."

**Why It Happens:**
Research feels like progress without the risk of failure. There's always one more question to answer. Analysis paralysis disguises itself as rigor. Fear of being wrong masquerades as thoroughness.

**The Fix:**
Set a hard deadline for decision-making. After 20-30 interviews, you have enough signal. Use the "Disagree and Commit" principle. Build the smallest thing that could test your riskiest assumption. Real learning comes from market contact, not research.

**Detection Pattern:**
- "We need more data before deciding"
- Validation phase extending beyond 4-6 weeks
- Multiple pivots based on research alone
- No time-boxed experiments
- Perfect information seeking

---

## 4. The "We're Different" Blindness

**Severity:** High

**The Trap:**
You dismiss competitors because "we're different." You believe your approach is unique and therefore competition doesn't apply. Meanwhile, customers see you as yet another option in a crowded market.

**Why It Happens:**
Founders are too close to see from customer's perspective. Technical differences feel significant from inside but invisible from outside. Optimism bias makes us underweight competitive threats.

**The Fix:**
Do the "Screenshot Test" - put your landing page next to 5 competitors. If a customer can't immediately see why you're different, you're not. Define your category or be defined by it. Your differentiation must be obvious in 5 seconds, not explained in 5 minutes.

**Detection Pattern:**
- "Our competitors don't really compete with us"
- Differentiation requires explanation
- Feature comparison shows similarity
- No clear category ownership
- Positioning by features, not outcomes

---

## 5. The Premature Scaling Death Spiral

**Severity:** Critical

**The Trap:**
You get early traction - a few paying customers, some press, maybe funding. You hire aggressively, build out the product, scale marketing. Then you realize you didn't actually have product-market fit. You had early adopter curiosity.

**Why It Happens:**
Pressure from investors to show growth. Early success creates false confidence. Hiring feels like progress. The difference between "some people want this" and "the market wants this" is subtle but fatal.

**The Fix:**
Define PMF metrics before scaling: 40%+ would be "very disappointed" without your product, organic word-of-mouth growth, low churn, customers expanding usage unprompted. Don't scale until these metrics are hit. Growth before PMF is pouring water into a leaky bucket.

**Detection Pattern:**
- Scaling before clear retention metrics
- High CAC with unclear LTV
- "Growth will solve our problems"
- Hiring ahead of validated demand
- Churn > 5% monthly for B2B, > 10% for B2C

---

## 6. The "Everyone Is Our Customer" Trap

**Severity:** High

**The Trap:**
Your target market is "anyone who needs X." You're afraid to narrow because you might miss opportunities. Your messaging is generic. Your product tries to serve everyone and delights no one.

**Why It Happens:**
Narrowing feels like leaving money on the table. Investors want big TAM numbers. "Small" markets feel limiting. We optimize for not missing anyone rather than deeply serving someone.

**The Fix:**
Start with the smallest viable market that can sustain your business. Be the only solution for someone rather than an option for everyone. Use Geoffrey Moore's targeting: specific person, specific situation, specific problem. You can expand later; you can't un-dilute focus.

**Detection Pattern:**
- Target market described as broad demographic
- "Our TAM is $X billion"
- Messaging uses generic value props
- No clear ideal customer profile (ICP)
- Features designed for "users" not specific personas

---

## 7. The Solution-First Backwards Build

**Severity:** High

**The Trap:**
You start with technology ("We'll use AI to...") or solution ("An app that lets you...") instead of problem. You retrofit problems to justify your solution. The problem you solve isn't the problem customers care about.

**Why It Happens:**
Solutions are exciting; problems are boring. Technology capabilities inspire ideas. We pattern-match from what's possible, not what's needed. "Build something cool" is more fun than "understand deep pain."

**The Fix:**
Force yourself to articulate the problem without mentioning your solution. Use the "5 Whys" to get to root cause. Interview customers about their workflow without mentioning what you're building. If you can't describe the problem in their words, you don't understand it.

**Detection Pattern:**
- Pitch starts with solution or technology
- Problem statement uses your terminology
- Customers don't recognize problem description
- "Looking for a problem" for your tech
- Features before use cases

---

## 8. The Feedback Whiplash

**Severity:** Medium

**The Trap:**
Every customer interview sends you in a new direction. Negative feedback triggers pivots. You oscillate between strategies based on the last conversation. Your product becomes a Frankenstein of different visions.

**Why It Happens:**
Individual feedback feels compelling in the moment. We want to be responsive. Pattern recognition across feedback is hard. Confirmation bias makes us overweight feedback that matches our fears.

**The Fix:**
Collect feedback in batches before acting. Look for patterns across 10+ conversations. Distinguish between feedback on execution vs. strategy. Create a "feedback parking lot" - log it, but don't act until you see patterns. One person's opinion is an anecdote; ten people's pattern is data.

**Detection Pattern:**
- Strategy changes after single conversations
- Product direction unclear to team
- Multiple pivots in short timeframe
- No documented feedback synthesis
- Acting on outlier opinions

---

## 9. The Vanity Metrics Mirage

**Severity:** High

**The Trap:**
Your dashboard shows growing users, downloads, pageviews, or followers. You celebrate these wins. But revenue is flat, retention is poor, and engagement is shallow. You're measuring activity, not value.

**Why It Happens:**
Vanity metrics go up and to the right - they feel good. Real metrics (retention, NPS, revenue per user) are harder and often embarrassing. We report what looks good, not what matters.

**The Fix:**
Define your One Metric That Matters (OMTM) - the single number that indicates product health. For most products: weekly active users who complete core action, or monthly retention. If users aren't coming back unprompted and doing the core thing repeatedly, nothing else matters.

**Detection Pattern:**
- Celebrating signups without activation
- No cohort retention analysis
- Engagement metrics without depth (opens vs. completes)
- Revenue growth without unit economics
- "Users" counted without defining active

---

## 10. The "V2 Will Fix It" Denial

**Severity:** High

**The Trap:**
Early users complain about core issues. You acknowledge but say "we'll fix it in V2." You keep building new features instead of fixing fundamentals. V2 never comes because you're always chasing growth.

**Why It Happens:**
New features are more exciting than fixing old problems. The backlog grows faster than you can address it. Core issues feel expensive to fix. There's always pressure to ship something new.

**The Fix:**
If something is broken in your core flow, stop everything until it's fixed. Technical debt and UX debt compound like financial debt. A product that does one thing flawlessly beats a product with ten features that all kind of work. "V2 will fix it" is the biggest lie in product.

**Detection Pattern:**
- Known issues in core flow unfixed for months
- "We'll fix it later" in sprint notes
- New features shipping while fundamentals broken
- Growing list of "known issues"
- User complaints about same issues over time

---

## 11. The Copycat Deathmatch

**Severity:** High

**The Trap:**
You see a successful product and build a "better" version. You copy their features but add your twist. You enter a crowded market hoping to out-execute. You find yourself in a features arms race with no differentiation.

**Why It Happens:**
Validated markets feel safer than new ones. "X but better" is an easy pitch. Copying reduces research burden. We underestimate incumbent advantages (brand, distribution, network effects).

**The Fix:**
Compete on a dimension incumbents can't or won't. Find the underserved segment the leader ignores. Change the game entirely rather than playing better. Ask: "What can I be the only one doing?" not "What can I do better?"

**Detection Pattern:**
- Product described as "X but better"
- Feature roadmap mirrors competitor
- No clear segment ownership
- Competing on price or features alone
- Incumbent could easily copy your differentiation

---

## 12. The "Users Don't Know What They Want" Excuse

**Severity:** Medium

**The Trap:**
You invoke the Jobs/Ford quote about customers not asking for cars/iPods to justify ignoring feedback. You believe your vision is superior to user input. You build what you think they need, not what they demonstrate they need.

**Why It Happens:**
The quote is misunderstood. It's easier to trust your instinct than synthesize feedback. Some founders have been right ignoring feedback (survivorship bias). User feedback requires interpretation, not literal implementation.

**The Fix:**
Users don't know what solution they want - they DO know what problems they have. Your job is understanding the problem deeply enough to invent the right solution. Jobs spent thousands of hours understanding user behavior before inventing. The iPod came from seeing people's relationship with music, not ignoring their input.

**Detection Pattern:**
- Dismissing feedback as "users don't get it"
- No customer behavior observation
- Building based on internal intuition alone
- Surprise when users don't adopt features
- "They'll understand when they see it"

## Decision Framework

# Decisions: Product Strategy

These are the critical decision points that determine product success. Use these frameworks when facing strategic crossroads.

---

## Decision 1: Build vs. Buy vs. Partner

**Context:** When you need functionality that isn't your core competency.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Build** | Full control, custom fit, potential moat | Slow, expensive, maintenance burden | Core to differentiation, unavailable elsewhere, unique requirements |
| **Buy** | Fast, proven, someone else maintains | Dependency, cost, less control | Non-core, commodity, speed critical |
| **Partner** | Leverage expertise, shared risk | Alignment issues, dependency, rev share | Strategic synergy, market access, capabilities gap |

**Framework:**
```
Is this core to our differentiation?
├── Yes → Build (invest in competitive advantage)
└── No → Continue

Does a good solution exist?
├── No → Build (no alternative)
└── Yes → Continue

Is speed critical?
├── Yes → Buy (time > money)
└── No → Build if strategic, Buy if commodity
```

**Default Recommendation:** Buy unless it's core to your value proposition. Build creates maintenance burden; only take it on for real differentiation.

---

## Decision 2: Horizontal vs. Vertical Product Strategy

**Context:** When deciding how to expand or focus your product.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Horizontal** | Larger TAM, more use cases | Shallow expertise, more competitors | Strong platform/infrastructure, network effects |
| **Vertical** | Deep expertise, defensible position | Smaller TAM, ceiling risk | Domain expertise, complex workflows, switching costs |

**Framework:**
```
Vertical Signals:
- Industry has unique workflows
- Compliance/regulation matters
- Trust and expertise valued
- Buyers want "built for us"

Horizontal Signals:
- Problem is universal
- Workflows are similar across industries
- Integration matters more than depth
- Network effects possible
```

**Default Recommendation:** Start vertical, expand horizontal. It's easier to add industries than to deepen expertise. Vertical builds credibility that horizontal can leverage.

---

## Decision 3: Free vs. Freemium vs. Paid

**Context:** When determining pricing strategy for new products.

**Options:**

| Model | Pros | Cons | Choose When |
|-------|------|------|-------------|
| **Free (ad-supported)** | Maximum reach, low friction | Need huge scale, ad dependency | Consumer, content, virality critical |
| **Freemium** | Reach + revenue, self-serve upgrade | Conversion optimization, support costs | Product sells itself, clear value ladder |
| **Free Trial** | Qualified leads, urgency | Short evaluation window, support burden | Complex products, sales-assisted |
| **Paid Only** | Qualified customers, cleaner economics | Slower growth, higher CAC | High-value B2B, premium positioning |

**Framework:**
```
Can users experience core value without human assistance?
├── No → Free Trial + Sales
└── Yes → Continue

Is there a natural upgrade trigger?
├── Yes → Freemium (upgrade when they hit limit)
└── No → Continue

Do you need maximum reach for network effects?
├── Yes → Free tier with premium features
└── No → Paid (with trial period)
```

**Default Recommendation:** Freemium for self-serve products, Free Trial + Sales for complex B2B. Pure free only if you have network effects or ads strategy.

---

## Decision 4: Speed vs. Quality Release

**Context:** When deciding what level of polish before shipping.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Ship Fast (MVP)** | Learn quickly, first mover | Technical debt, brand risk | New market, unvalidated assumptions, reversible |
| **Ship Polish** | Better first impression, less rework | Slower learning, might build wrong thing | Known market, brand matters, irreversible |

**Framework:**
```
How confident are you in the solution?
├── Low (<50%) → Ship fast, learn, iterate
└── High (>80%) → Consider polish

Is first impression critical?
├── Yes (enterprise, premium) → Polish more
└── No (early adopters, tech-savvy) → Ship fast

Can you recover from bad v1?
├── Yes → Ship fast
└── No → Polish
```

**Default Recommendation:** When in doubt, ship faster. The learning from real users almost always exceeds the benefit of additional polish. "If you're not embarrassed by v1, you launched too late."

---

## Decision 5: Feature Depth vs. Feature Breadth

**Context:** When allocating engineering resources.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Go Deep** | Best-in-class at core, defensible | Narrow use case, market ceiling | Differentiation through excellence, expert users |
| **Go Broad** | More use cases, larger market | "Jack of all trades", harder to defend | Platform play, SMB market, price competition |

**Framework:**
```
What would make users say "this is the best X I've ever used"?
- If it's ONE thing done brilliantly → Go deep
- If it's everything working together → Go broad

Who's your customer?
- Expert users → Go deep (they notice quality)
- Generalist users → Go broad (they want convenience)

What's your moat?
- Technology/expertise → Go deep
- Distribution/ecosystem → Go broad
```

**Default Recommendation:** Go deep first, then broaden. It's easier to expand a product people love than to fix a product people tolerate.

---

## Decision 6: Own vs. Integrate

**Context:** When adjacent functionality is needed.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Own** | Full control, seamless UX, margin | Build + maintain cost, slower | Core to experience, competitive advantage |
| **Integrate** | Faster, leverage existing, ecosystem | Dependency, rev share, UX gaps | Non-core, strong partners exist, speed critical |

**Framework:**
```
Does owning this make our core product significantly better?
├── Yes → Lean toward own
└── No → Lean toward integrate

Would users prefer a specialist solution?
├── Yes → Integrate (don't fight user preference)
└── No → Own (capture value)

Can we do this better than partners?
├── No → Integrate
└── Yes → Consider own (if strategic)
```

**Default Recommendation:** Integrate by default. Own only when it's strategic to the core product experience. "Not Invented Here" syndrome kills companies.

---

## Decision 7: Self-Serve vs. Sales-Assisted

**Context:** When determining go-to-market model.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Self-Serve** | Scalable, lower CAC, faster feedback | Limited ASP, support burden | Simple product, SMB market, viral potential |
| **Sales-Assisted** | Higher ASP, handle complexity, enterprise | Expensive, slower, requires sales org | Complex product, enterprise market, high ACV |
| **Hybrid** | Best of both, segment coverage | Operational complexity, channel conflict | Wide market range, multiple segments |

**Framework:**
```
Can a user get value without talking to a human?
├── Yes → Self-serve viable
└── No → Sales-assisted required

Target ACV:
- <$1K/year → Self-serve only
- $1K-$25K/year → Self-serve + inside sales
- >$25K/year → Sales-assisted
- >$100K/year → Enterprise sales

Buyer complexity:
- Single buyer → Self-serve
- Multiple stakeholders → Sales-assisted
```

**Default Recommendation:** Start self-serve, add sales when you see larger deals getting stuck. It's easier to add sales than to make a sales-dependent product self-serve.

---

## Decision 8: Platform vs. Product

**Context:** When you see potential for others to build on your work.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Product** | Focused, faster iteration, simpler | Limited scale, do everything yourself | Early stage, unproven market, execution speed |
| **Platform** | Ecosystem leverage, network effects | Complexity, chicken-egg problem, loss of control | Proven product, ecosystem demand, can't do everything yourself |

**Framework:**
```
Do you have a successful product already?
├── No → Build product first
└── Yes → Continue

Are others building workarounds/integrations?
├── No → Stay product
└── Yes → Consider platform

Can you attract quality developers/partners?
├── No → Stay product
└── Yes → Platform viable
```

**Default Recommendation:** Product first, platform later. Extract the platform from a working product, don't build it speculatively. Every successful platform started as a successful product.

---

## Decision 9: Single Product vs. Multi-Product

**Context:** When considering expanding product portfolio.

**Options:**

| Option | Pros | Cons | Choose When |
|--------|------|------|-------------|
| **Single Product** | Focus, simpler org, clear brand | Growth ceiling, single point of failure | Pre-PMF, limited resources, core product not mature |
| **Multi-Product** | Multiple growth vectors, cross-sell, resilience | Complexity, resource split, org challenges | Strong core product, natural adjacencies, excess resources |

**Framework:**
```
Is your core product at full potential?
├── No → Focus on core
└── Yes → Continue

Do you have clear product-market fit?
├── No → Focus on core
└── Yes → Continue

Is there natural adjacency?
├── Yes → Second product viable
└── No → Stay single product

Can you resource it without hurting core?
├── No → Stay single product
└── Yes → Consider second product
```

**Default Recommendation:** Single product until it's clearly working. Most second products are distractions from fixing the first. Be honest about whether core is truly mature.

---

## Decision 10: Pricing: Value-Based vs. Cost-Plus vs. Competitive

**Context:** When setting prices for products.

**Options:**

| Approach | Pros | Cons | Choose When |
|----------|------|------|-------------|
| **Value-Based** | Capture more value, premium positioning | Requires quantifying value, harder to explain | Clear ROI, differentiated product, sophisticated buyers |
| **Cost-Plus** | Simple, defensible margin | Leaves money on table, commoditizes | Commodity product, price-sensitive market |
| **Competitive** | Easy to justify, market-validated | Race to bottom, no differentiation | Crowded market, similar products, must win on price |

**Framework:**
```
Can you quantify the value you create?
├── Yes → Value-based pricing
└── No → Continue

Is your product differentiated?
├── No → Competitive pricing
└── Yes → Value-based or premium positioning

How sophisticated are buyers?
├── Enterprise/sophisticated → Value-based
└── SMB/consumers → Simple tiers
```

**Default Recommendation:** Value-based pricing whenever possible. It forces you to articulate and deliver clear value. Cost-plus and competitive pricing are races to the bottom.

## Collaboration

### When to Hand Off

| Trigger | Delegate To | Context |
|---------|-------------|--------|
| `growth|acquisition|retention|viral` | growth-strategy | Product needs growth strategy |
| `brand|positioning|messaging` | brand-positioning | Product needs brand strategy |
| `roadmap|features|backlog` | product-management | Strategy needs execution planning |
| `design|ux|interface` | ux-design | Strategy needs UX translation |

### Receives Work From

- **founder-operating-system**: Founder needs product direction
- **growth-strategy**: Growth needs product alignment
- **brand-positioning**: Brand needs product support
- **product-management**: PM needs strategic guidance

### Works Well With

- brand-positioning
- growth-strategy
- ux-design
- marketing
- product-management

---

## Get the Full Version

This skill has **automated validations**, **detection patterns**, and **structured handoff triggers** that work with the Spawner orchestrator.

```bash
npx vibeship-spawner-skills install
```

Full skill path: `~/.spawner/skills/strategy/product-strategy/`

**Includes:**
- `skill.yaml` - Structured skill definition
- `sharp-edges.yaml` - Machine-parseable gotchas with detection patterns
- `validations.yaml` - Automated code checks
- `collaboration.yaml` - Handoff triggers for skill orchestration

**Deep content:**
- `patterns.md` - Comprehensive pattern library
- `anti-patterns.md` - What to avoid and why
- `sharp-edges.md` - Detailed gotcha documentation
- `decisions.md` - Decision frameworks

---

*Generated by [VibeShip Spawner](https://github.com/vibeforge1111/vibeship-spawner-skills)*
