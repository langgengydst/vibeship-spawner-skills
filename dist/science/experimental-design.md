# Experimental Design

> Formal Design of Experiments (DOE) methodology for maximizing information
from experiments while minimizing resources. Covers factorial designs,
blocking, randomization, and optimal design strategies.


**Category:** science | **Version:** 1.0.0

---

## Patterns


## Sharp Edges (Gotchas)

*Real production issues that cause outages and bugs.*

### [CRITICAL] OFAT requires more runs and can never detect interaction effects

**Why it happens:**
OFAT assumes factors are independent. In reality, factor A's
effect often depends on factor B's level (interaction).
Factorial designs detect these interactions.

OFAT also requires MORE total runs for the same information.


**Solution:**
```
Use factorial design:
from pyDOE2 import ff2n
design = ff2n(2)  # 2 factors, 4 runs
# Tests all combinations including interaction

```

**Symptoms:**
- Changing one variable at a time
- Optimal found but doesn't work in practice
- Variables tested independently

---

### [CRITICAL] Running all treatment A first biases results with time effects

**Why it happens:**
Equipment drifts over time. Operators get fatigued.
Materials age. If all treatment A runs are first,
time effects get confounded with treatment effects.


**Solution:**
```
np.random.shuffle(run_order)
# Run experiments in random order
# Or use blocking if time effects are expected

```

**Symptoms:**
- Experiments run in convenient order
- All replicates of condition X run consecutively
- Unexpected 'treatment effects'

---

### [HIGH] Linear model fit when relationship is actually curved

**Solution:**
```
# Add center points to 2-level factorial
design = np.vstack([
    ff2n(2),           # Corner points
    [[0, 0], [0, 0]]   # Center points (replicates)
])
# If center point response differs from corner average,
# curvature exists â†’ need higher-order model

```

**Symptoms:**
- 2-level factorial shows no effect
- Optimal settings don't work as expected
- Model has poor prediction accuracy

---

### [HIGH] In fractional designs, some effects are mathematically confounded

**Why it happens:**
Fractional factorials trade runs for information.
Resolution III: Main effects aliased with 2-way interactions
Resolution IV: Main effects clear, 2-way aliased with 2-way
Resolution V: Main and 2-way clear, aliased with 3-way


**Solution:**
```
# Check resolution before interpreting
# Use Resolution V or higher for main + 2-way interactions
# Or use foldover to de-alias

```

**Symptoms:**
- Using fractional factorial without understanding resolution
- Main effect 'significant' but actually aliased with interaction

---

### [MEDIUM] Without replicates, can't distinguish signal from noise

**Solution:**
```
# Include replicates, especially at center points
design = full_factorial(factors)
design = pd.concat([design, design])  # Duplicate for replicates
# Or at minimum, replicate center points

```

**Symptoms:**
- One run per condition
- Every effect looks 'significant'
- No pure error estimate

---

## Collaboration

### When to Hand Off

| Trigger | Delegate To | Context |
|---------|-------------|--------|
| `power|sample size|n required` | statistical-analysis | Need sample size calculation |
| `response surface|optimization` | optimization | Need to find optimal settings |

### Receives Work From

- **scientific-method**: Need formal experimental design
- **performance-profiling**: Need design for benchmark experiments

---

## Get the Full Version

This skill has **automated validations**, **detection patterns**, and **structured handoff triggers** that work with the Spawner orchestrator.

```bash
npx vibeship-spawner-skills install
```

Full skill path: `~/.spawner/skills/science/experimental-design/`

**Includes:**
- `skill.yaml` - Structured skill definition
- `sharp-edges.yaml` - Machine-parseable gotchas with detection patterns
- `validations.yaml` - Automated code checks
- `collaboration.yaml` - Handoff triggers for skill orchestration

---

*Generated by [VibeShip Spawner](https://github.com/vibeforge1111/vibeship-spawner-skills)*
