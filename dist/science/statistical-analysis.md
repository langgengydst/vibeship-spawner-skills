# Statistical Analysis

> Comprehensive statistical analysis for research, experiments, and data science.
Covers hypothesis testing, effect sizes, confidence intervals, Bayesian methods,
regression, and advanced techniques. Emphasizes correct interpretation and
avoiding common statistical mistakes.


**Category:** science | **Version:** 1.0.0

---

## Patterns


## Sharp Edges (Gotchas)

*Real production issues that cause outages and bugs.*

### [CRITICAL] Normality tests lack power for small samples - exactly when normality matters

**Why it happens:**
With small n, normality tests have low power - they often
fail to reject even clearly non-normal data. With large n,
they reject trivial deviations that don't affect t-test validity.


**Solution:**
```
1. Use Q-Q plots for visual inspection
2. For small n, prefer robust/non-parametric methods
3. For large n, visual check matters more than test
4. Non-significant ≠ evidence of normality

```

**Symptoms:**
- Shapiro-Wilk p > 0.05 with n=15
- Using t-test because 'normality passed'
- Non-significant test treated as proof of normality

---

### [CRITICAL] High correlations can be entirely spurious due to confounding

**Why it happens:**
Shoe size correlates with reading ability (r≈0.7).
Cause: Age affects both. In complex systems, confounders
are often unmeasured or unknown.


**Solution:**
```
1. Draw causal diagram (DAG) before analysis
2. For causal claims, use experimental designs
3. For observational data, use causal inference methods
4. State limitations explicitly

```

**Symptoms:**
- High correlation between X and Y
- Recommending intervention on X to change Y
- No consideration of confounding variables

---

### [HIGH] Using independent test on paired data loses power; vice versa inflates errors

**Solution:**
```
Same subject at different times → Paired (ttest_rel)
Random samples from populations → Independent (ttest_ind)

```

**Symptoms:**
- Pre-post measurements analyzed as independent
- Same subjects in both conditions analyzed independently

---

### [HIGH] Significant ANOVA requires post-hoc tests to identify which pairs differ

**Solution:**
```
Use post-hoc tests: Tukey HSD, Bonferroni, or Dunnett
from statsmodels.stats.multicomp import pairwise_tukeyhsd

```

**Symptoms:**
- ANOVA p < 0.05, then directly comparing specific pairs
- Multiple t-tests after ANOVA without correction

---

### [HIGH] Predictions outside observed range can be wildly wrong

**Solution:**
```
1. Only predict within observed data range
2. If extrapolation needed, use uncertainty bounds
3. Consider non-linear models that asymptote appropriately

```

**Symptoms:**
- Predicting beyond range of training data
- Model used for forecasting far into future

---

### [HIGH] A trend in aggregated data can reverse when stratified

**Solution:**
```
1. Always stratify by potential confounders
2. Use regression to control for confounders
3. Report both aggregate and stratified results

```

**Symptoms:**
- Treatment looks better overall but worse in every subgroup
- Opposite conclusions from aggregate vs stratified analysis

---

### [MEDIUM] P(A|B) ≠ P(B|A) - ignoring base rates gives wrong probabilities

**Why it happens:**
99% accurate test for 1/1000 disease: positive predictive
value is only ~9%, not 99%. Most positives are false positives.


**Solution:**
```
Use Bayes' theorem. Report PPV and NPV, not just sensitivity.

```

**Symptoms:**
- Confusing sensitivity with positive predictive value
- Test 99% accurate → 99% confident in positive result

---

### [MEDIUM] 50% relative risk reduction can be 0.1% absolute reduction

**Solution:**
```
Always report absolute risk and NNT alongside relative risk.

```

**Symptoms:**
- Drug reduces risk by 50%!
- Ignoring baseline risk in relative measures

---

## Collaboration

### When to Hand Off

| Trigger | Delegate To | Context |
|---------|-------------|--------|
| `bayesian|prior|posterior` | bayesian-methods | Need Bayesian statistical analysis |
| `causal|intervention|treatment effect` | causal-inference | Need causal inference from observational data |
| `meta-analysis|combine studies` | literature-review | Need to synthesize multiple study results |

### Receives Work From

- **scientific-method**: Need to analyze experimental data
- **ml-ops**: Need statistical comparison of model performance
- **data-pipeline**: Need to analyze processed data

---

## Get the Full Version

This skill has **automated validations**, **detection patterns**, and **structured handoff triggers** that work with the Spawner orchestrator.

```bash
npx vibeship-spawner-skills install
```

Full skill path: `~/.spawner/skills/science/statistical-analysis/`

**Includes:**
- `skill.yaml` - Structured skill definition
- `sharp-edges.yaml` - Machine-parseable gotchas with detection patterns
- `validations.yaml` - Automated code checks
- `collaboration.yaml` - Handoff triggers for skill orchestration

---

*Generated by [VibeShip Spawner](https://github.com/vibeforge1111/vibeship-spawner-skills)*
