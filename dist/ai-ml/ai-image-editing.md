# AI Image Editing

> Expert patterns for AI-powered image editing including inpainting, outpainting, ControlNet, image-to-image, and API integration with Replicate, Stability AI, and Fal

**Category:** ai-ml | **Version:** 1.0.0

**Tags:** image-editing, inpainting, outpainting, controlnet, stable-diffusion, flux, replicate, stability-ai, comfyui

---

## Patterns

### Inpainting with Replicate API
Use Replicate's Flux Fill model for professional inpainting.
Mask white areas to be filled, black to preserve.

Model options:
- flux-fill-pro: Best quality, seamless blending
- flux-dev-inpainting: Good balance of speed/quality
- sdxl-inpainting: SDXL-based, lower cost


### Stability AI Search and Replace
Replace objects without creating masks manually.
Describe what to find and what to replace it with.

Available on AWS Bedrock and direct API.
No mask required - AI automatically segments.


### Outpainting and Image Extension
Extend images beyond original boundaries.
AI generates seamless content matching style.

Key concepts:
- Extend in any direction (left, right, up, down)
- Maintain color/style consistency
- Handle aspect ratio changes


### ControlNet Structure Control
Control image generation with structural guidance.

Control types:
- Canny: Edge detection, sharp boundaries
- Depth: 3D spatial relationships
- Pose: Human body positioning
- HED/Soft Edge: Organic, softer boundaries

Combine multiple controls for precise results.


### Image-to-Image Transformation
Transform existing images with style/content changes.
Control transformation strength to balance original vs new.

Use cases:
- Style transfer (photo to art)
- Retexturing (change materials/surfaces)
- Color grading
- Detail enhancement


### Multi-Step Iterative Editing
Chain multiple editing operations for complex results.
Each step builds on the previous, enabling sophisticated edits.

Strategy:
1. Use lower denoise per step
2. Expand masks gradually
3. Verify intermediate results


### Content Moderation for Generated Images
Ensure generated images comply with content policies.
Check both inputs and outputs for safety.

Key concerns:
- NSFW/explicit content
- Violence/gore
- Hate symbols
- Deepfakes/impersonation



## Sharp Edges (Gotchas)

*Real production issues that cause outages and bugs.*

### [HIGH] undefined

---

### [HIGH] undefined

---

### [HIGH] undefined

---

### [HIGH] undefined

---

### [MEDIUM] undefined

---

### [HIGH] undefined

---

### [CRITICAL] undefined

---

### [MEDIUM] undefined

---

### [MEDIUM] undefined

---

## Collaboration

### When to Hand Off

| Trigger | Delegate To | Context |
|---------|-------------|--------|
| `user needs video from images` | text-to-video | Image-to-video animation |
| `user needs 3D from images` | 3d-generation | Image to 3D model |
| `user needs batch processing` | workflow-automation | Image processing pipelines |
| `user needs local inference` | on-device-ai | Run models locally |
| `user needs content moderation` | ai-safety-alignment | NSFW detection and filtering |

---

## Get the Full Version

This skill has **automated validations**, **detection patterns**, and **structured handoff triggers** that work with the Spawner orchestrator.

```bash
npx vibeship-spawner-skills install
```

Full skill path: `~/.spawner/skills/ai-ml/ai-image-editing/`

**Includes:**
- `skill.yaml` - Structured skill definition
- `sharp-edges.yaml` - Machine-parseable gotchas with detection patterns
- `validations.yaml` - Automated code checks
- `collaboration.yaml` - Handoff triggers for skill orchestration

---

*Generated by [VibeShip Spawner](https://github.com/vibeforge1111/vibeship-spawner-skills)*
