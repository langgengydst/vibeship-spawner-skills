# Research AI Tools - Sharp Edges
# Gotchas when using AI for research

sharp_edges:
  - id: hallucination-as-fact
    summary: "AI confidently states false information"
    severity: critical
    tools_affected: [chatgpt, claude, gemini]
    situation: "AI provides plausible but incorrect information"
    why: |
      AI can:
      - Invent statistics
      - Create fake citations
      - Mix up facts
      - State speculation as fact
    solution: |
      1. Verify important claims
      2. Use citation-based tools (Perplexity)
      3. Cross-reference sources
      4. Be skeptical of specifics

  - id: outdated-information
    summary: "AI has knowledge cutoff, misses recent events"
    severity: high
    tools_affected: [chatgpt, claude]
    situation: "Asking about recent events"
    why: |
      Training data has cutoff dates.
      AI doesn't know recent events without browsing.
    solution: |
      1. Use Perplexity for current info
      2. Enable web browsing if available
      3. Check publication dates
      4. Verify against current sources

  - id: source-quality-blind
    summary: "AI cites sources without evaluating quality"
    severity: high
    tools_affected: [perplexity]
    situation: "AI cites blogs and press releases as authority"
    why: |
      AI finds relevant text, not reliable sources.
      Blog posts treated same as peer review.
    solution: |
      1. Evaluate source credibility
      2. Prefer primary sources
      3. Check author credentials
      4. Use Consensus for academic claims

  - id: context-collapse
    summary: "Nuanced research simplified to misleading summary"
    severity: medium
    tools_affected: [all]
    situation: "Complex topic reduced to simple answer"
    why: |
      AI summarization loses:
      - Caveats and limitations
      - Methodological concerns
      - Minority views
      - Context
    solution: |
      1. Read original sources
      2. Ask about limitations
      3. Request nuance explicitly
      4. Multiple perspectives

  - id: echo-chamber-research
    summary: "AI confirms what you want to hear"
    severity: medium
    tools_affected: [all]
    situation: "Leading questions get confirming answers"
    why: |
      AI tends to agree with premise.
      Confirmation bias amplified.
    solution: |
      1. Ask neutral questions
      2. Ask for counterarguments
      3. Seek disconfirming evidence
      4. Devil's advocate prompts

  - id: academic-paywall
    summary: "AI references papers you can't access"
    severity: low
    tools_affected: [elicit, consensus]
    situation: "Found perfect paper, behind $40 paywall"
    why: |
      Most academic papers paywalled.
      AI can see abstracts but not full text.
    solution: |
      1. Sci-Hub (legally gray)
      2. Library access
      3. Author direct contact
      4. Preprint servers (arXiv)
